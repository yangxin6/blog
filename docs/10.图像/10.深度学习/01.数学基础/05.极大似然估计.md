---
title: 极大似然估计
date: 2021-09-18 16:00:00
permalink: /pages/k5v1Xy
categories: 
  - 深度学习
author: 
  name: yangxin
  link: https://github.com/yangxin6/DeepLearning
---



## 步骤

假设随机变量 $X\sim P(x,\theta)$，现有样本 $x_1,...,x_n$，

定义似然函数为 $\tilde{L} = P(x_1,\theta)...P(x_n,\theta)$

对数似然函数为 $L=ln \tilde{L}=ln[P(x_1,\theta)...P(x_n,\theta)]$

极大似然估计为 $max\ L$



## 高斯分布

$p(x)=\frac1{\sqrt{2\pi}\sigma} e^{-\frac{(x-u)^2}{2\sigma^2}}$

样本 $x_1,...,x_n$

$L = ln[\frac1{\sqrt{2\pi}\sigma} e^{-\frac{(x_1-u)^2}{2\sigma^2}},...,\frac1{\sqrt{2\pi}\sigma} e^{-\frac{(x_N-u)^2}{2\sigma^2}}]$

$L = -Nln\sqrt{2\pi} - Nln-[\frac{(x_1-u)^2}{2\sigma^2}+...+\frac{(x_N-u)^2}{2\sigma^2}]$

$\frac{\part L}{\part u}=2(x_1-u)+...+2(x_N-u)=0$  $\Rightarrow u=\frac{x_1+...+x_n}{N}$

$\frac{\part L}{\part u}=0 \Rightarrow -\frac{N}{\sigma} + \frac{\sum_i(x-u_i)^2}{\sigma^3} = 0$  $\Rightarrow \sigma^2 = \frac{\sum_{i=1}^N(x_i-u)^2}{N}$ 



**极大似然估计，误差的高斯分布与最小二乘估计的等价性**

$x_i,...,x_N,x_i\in R^n$

$y_i,...,y_N,y_i\in R^n$

$y_i = w^Tx_i,w\in R^n$

拟合误差： $e_i=y_i-w^Tx_i$

若设 $e_i \sim N(0,1)$

即 $e_i \sim \frac1{\sqrt{2\pi}}e^{-\frac{e^2}2}$

似然函数： $L = ln[\frac1{\sqrt{2\pi}\sigma} e^{-\frac{-e_1^2}2},...,\frac1{\sqrt{2\pi}\sigma} e^{-\frac{-e_N^2}2}] = -Nln\sqrt{2\pi}-\frac12(e_1^2+...+e_N^2)$

最大化 $L$ 等价于     最小化 $(e_1^2+...+e_N^2)$

即 $min\ [(y_1-w^Tx_1)^2+...+(y_N-w^Tx_N)^2]=J$

