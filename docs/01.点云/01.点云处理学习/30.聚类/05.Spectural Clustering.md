---
title: 谱聚类
date: 2021-09-09 13:00:00
permalink: /pages/u868P1
categories: 
  - 点云
tags: 
  - false
author: 
  name: yangxin
  link: https://github.com/yangxin6/3DPointCloud
---

谱聚类：在图的层面工作，而不是欧氏距离，关注点与点之间的连接性。在不规则的情况下可以选择谱聚类。



## 无向图

- 谱聚类 工作在 无向图G上，$G=(V,E), where V ={v_1,...,v_n}$

- 两个节点 $v_i,v_j$ 的边 规定为权重 $w_{ij} \geq 0$
  - 如果两个节点之间没有连接，$w_{ij} = 0$
  - 规定对角线元素 都为0，即 $w_{ii}=0$
- 加权的邻接矩阵/相似矩阵表示为 $W = (w_{ij})_{i,j=1,...,n}$

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/W.5lyhzkh06r40.png" alt="W" style="zoom:73%;" />

## 构建无向图

- 每个点都是一个节点
-  有3种常用的为谱聚类构建无向图的方法
  1. $\epsilon$-neighborhood Graph. Radius 邻近搜索。离一个点多远范围内的点都建立连线，$w_{i,j}=d(v_i,v_j)$
  2. k-neighborhood Graph. kNN搜索。每个节点直选离它最近的 k 个节点建立连线，$w_{i,j}=d(v_i,v_j)$
     - 如果 $v_i$ 是 $v_j$ 的其中一个 knn <mark>或</mark>  $v_j$ 是 $v_i$ 的其中一个 knn，则建立连线
     -  如果 $v_i$ 是 $v_j$ 的其中一个 knn <mark>且</mark>  $v_j$ 是 $v_i$ 的其中一个 knn，则建立连线
  3. 每一个节点之间都有连线，连线的权重 就是 相似度（距离的导数）



## 拉普拉斯矩阵

- Degree Matrix D
  - 对角线上为 $d_1,...,d_n$ 的对角矩阵
  - $d_i= \sum^n_{j=1}w_{ij}$ ，$d_i$ 是 相似矩阵 $W$的每行元素之和
-  未归一化的 拉普拉斯矩阵 $L = D - W$
- 归一化的 拉普拉斯矩阵：
  - $L_{sym} = D^{-1/2}LD^{-1/2} = I - D^{-1/2}WD^{-1/2}$
  - $L_{rw} = D^{-1}L = I - D^{-1}W$



## 未归一化的谱聚类

- $W$ 相似矩阵，$D$ 对角阵，拉普拉斯矩阵 $L = D-W$

**步骤**

1. **根据数据点建立相似矩阵 $W \in R^{n*n}$** 。
2. 为归一化的拉普拉斯矩阵 $L = D - W$。
3. **计算出 $L$ 的最小的 $k$ 个特征向量 $v_1,...,v_k$。**
4. 定义矩阵 $V \in R^{n*k}$，为特征向量$v_1,...,v_k$ 组成的矩阵。
5. $y_i$ 为 特征向量 $V$ 的第 $i-th$ 行
6. **对 $y_i$ 做 k-means从而得到 $C_1,...,C_k$ 个类**
7. 输出所有的类：$A_1,...,A_k$，其中 $A_i = \{j|y_j \in C_i\}$





## 归一化的谱聚类



1. **根据数据点建立相似矩阵 $W \in R^{n*n}$** 。
2. 为归一化的拉普拉斯矩阵 $L^{'} = L_{rw}$。
3. **计算出 $L$ 的最小的 $k$ 个特征向量 $v_1,...,v_k$。**
4. 定义矩阵 $V \in R^{n*k}$，为特征向量$v_1,...,v_k$ 组成的矩阵。
5. $y_i$ 为 特征向量 $V$ 的第 $i-th$ 行
6. **对 $y_i$ 做 k-means从而得到 $C_1,...,C_k$ 个类**
7. 输出所有的类：$A_1,...,A_k$，其中 $A_i = \{j|y_j \in C_i\}$



## 区别

未归一化的谱聚类：更倾向于 每一个类里面的数据是均等的。

已归一化的谱聚类：更倾向于 每个类里面的粒度是接近的。

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/sp0.3zuxdrnd2sg0.png" alt="sp0" style="zoom:50%;" />

通常归一化谱聚类在点密度不均匀的情况下效果很好。

## 实例

k 的选择可能会造成不同的结果，（左为 k=3，右为k=2）

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/sp1.2jty0q0w1020.jpg" alt="sp1" style="zoom:56%;" />

## Eigen-gap

- Eigen-gap：两个特征值之间的差距非常大
- $\Delta_k = |\lambda_k - \lambda_{k-1}|$

如下图所示，第4个和第5个特征值差距较大，则 k=4 比较好。

![sp2](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/sp2.3ca9ks9lbug0.jpg)

## 总结

- 复杂度：$O(n^3)$
  - k-means 的复杂度 $O(t * k * n * d)$
- 优点：
  - 不会对每个类的形状有 任何的假设
  - 工作在图论上(连接性)，而不是欧几里得距离,
  - 可以对任何维度的数据操作
  - 自动发掘多少个类

- 缺点：
  - 时间复杂度较高
