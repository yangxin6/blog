---
title: 深度学习介绍
date: 2021-09-21 10:46:00
permalink: /pages/UjPvK8
categories: 
  - 点云
tags: 
  - false
author: 
  name: yangxin
  link: https://github.com/yangxin6/3DPointCloud
---

向量和矩阵的求导：

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/delta.187vt6i4t3kw.png" alt="delta" style="zoom:60%;" />

<img src="https://raw.githubusercontent.com/yangxin6/img-hosting/master/images/delta1.2r0wlboyk2m0.png" alt="delta1" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/telta2.4j0yo3nxm8i0.png" alt="telta2" style="zoom:50%;" />

## 表达形式

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/net0.11tru4psjur4.png" alt="net0" style="zoom:67%;" />

**激活函数**是为了把一个模型从**线性**变为**非线性**。

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/structure.36hwzexcp8w0.png" alt="structure" style="zoom:67%;" />



## 损失函数

简单的 Loss：

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/loss.69d5ke71ww00.png" alt="loss" style="zoom:47%;" />

**交叉熵**：

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/crossentropy.4uscwayivk80.png" alt="crossentropy" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/crossentropy2.7g54qmb23yg0.png" alt="crossentropy2" style="zoom:50%;" />

## MLP

Multi-Layer Perceptron（多层感知器）

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/mlp.twfa8ib6qf4.png" alt="mlp" style="zoom:50%;" />

- 神经元个数 
  - $4 + 2 = 6$
  - 不算输出
- 训练参数
  - $3 \times 4 + 4 \times 2 = 20$
- 输出 
  - $y=w^T_2(w^T_1x)=w^{'T}_2$
- 无论MLP有多少层都是线性的



## XOR

异或规则：

- $XOR(0,0)=XOR(1,1)=0$
- $XOR(0,1)=XOR(1,0)=1$

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/XOR.60es7du0uwc0.jpg" alt="XOR" style="zoom:50%;" />

线性模型无法模拟这种异或规则。



## 激活函数

$y=g(f(x))=g(w^Tx)$

- ReLU
- ELU

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/activation.2r70d3rg9hy0.png" alt="activation" style="zoom:50%;" />



## FC

Fully Connected Network (FC) 全连接网络

- 具有激活和 大于等于1个隐藏层的 的MLP
- 能够模拟任何函数 $f(x)$，其中 x 是输入

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/mlp.twfa8ib6qf4.png" alt="mlp" style="zoom:50%;" />

## 训练MLP

- 梯度下降
  - $w_{n+1}=w_n - \lambda \frac{\part L}{\part w}, \forall w$

- 反向传播



## CNN

Convolution Neural Network 卷积神经网络

 ![cnn](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/cnn.3uyyzvg1c8m0.jpg)



### CNN vs MLP

1. 更少的连接
   - 更少的参数
   - 更少的过拟合
2. 权重共享
   - 更少的过拟合
3. 局部不变量
   - 特征不应依赖于图像内的位置
   - 无论物体在图像中的哪个位置，都进行相同的预测

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/cnnvsmlp.2t76mr9y3l00.jpg" alt="cnnvsmlp" style="zoom:51%;" />





### 1D

#### 卷积核

$y_t = \sum \limits^{k}_{i=0} w_i \  \cdot \ x_{t+i}$   <img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/1D.444tr6zl06u0.jpg" alt="1D" style="zoom:67%;" />

- 核/过滤器 （kernal/filter）$w$ 
  - 长度 k
  - 未知/可训练的参数
- 输入 $x$
  - 长度 n
  - 感知域: $[x_t,t_{t+1},...,t_{t+k-1}]$
  - 每个感知域产生一个输出值 $y_t$
- 输出 $y$
  - 长度 $o$



#### Padding

解决边界问题

- 卷积核大小（kernel size）k
- 输入大小 n

- 输出
  - 无 padding：$o=n-k+1$
  - 有 padding：$o=(n+p)-k+1$

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/padding.wod5q4z6bxs.jpg" alt="padding" style="zoom:50%;" />



#### Stride

- 减少计算
- 增加感知域
- 输出
  - $o=\lfloor\frac{n+p-k}{s}\rfloor+1$ （向下取整）

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/stride.32sozyqhp5o0.jpg" alt="stride" style="zoom:67%;" /> <img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/stride2.2ci9awbujz0g.png" alt="stride2" style="zoom:87%;" />

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/stride3.3k74en9a4wy0.jpg" alt="stride3" style="zoom:63%;" />

### 2D

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/2D.5nc4iozdyds0.jpg" alt="2D" style="zoom:48%;" />

#### Kernel

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/kernal.218l4dmb8qsg.png" alt="kernal" style="zoom:57%;" />

#### Padding & Stride

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/ps.1jyhoib2kw1s.png" alt="ps" style="zoom:80%;" />

#### 多卷积核

多特征 => 多卷积核

- **单通道**

![mk](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/mk.41sjhl9yxmg0.png)



- **多通道**

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/mmk.y58ny2ynq0g.png" alt="mmk" style="zoom:67%;" />

#### 池化（Pooling）



- 汇总每个感知域中的信息
  - 最大限度
  - 平均数
- 没有可训练的参数
- 输入通道 = 输出通道 
  - $c_i=c_o$
- 相同的填充/步幅方法

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/pool.6gyhny579340.jpg" alt="pool" style="zoom:49%;" />

**Max Pooling**

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/maxpool.4o911yj9vp80.jpg" alt="maxpool" style="zoom:67%;" />

#### 总结

- $c_o$ 个 kernels，相同的 stride 和 padding
- 参数大小： $c_o \times k_h \times k_w \times c_i$
- 输出形状
  - $(c_o,o_h,o_w)=(c_o,\lfloor\frac{n_h+p_h-k_h}{s_h}\rfloor+1,\lfloor\frac{n_w+p_w-k_w}{s_w}\rfloor+1)$

- 复杂度
  - $O((c_o\times k_h \times k_w \times c_i)\times(o_h \times o_w))$



### 3D 

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/3D.2m13yni1r2o0.jpg" alt="3D" style="zoom:36%;" />

- 蓝色：输入
  - 每个小立方体包含 $d$ 个特征/通道 
- 橙色：内核
  - 每个小立方体包含 $d$ 个权重
- 绿色：输出
  - 每个小立方体都是一个标量。
  -  有 $o$ 个绿色方块

