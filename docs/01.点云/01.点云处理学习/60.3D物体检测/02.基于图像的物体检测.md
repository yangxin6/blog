---
title: 基于图像的物体检测
date: 2021-09-28 12:00:00
permalink: /pages/tJS2l5
categories: 
  - 点云
tags: 
  - false
author: 
  name: yangxin
  link: https://github.com/yangxin6/3DPointCloud
---

## 目标检测里程碑

![m](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/m.540ywoytyoo0.png)



## Two Stage

### RCNN

- 检测 = 定位 + 分类
  - 分类很容易
  - 如果我们可以在其他地方获得**区域建议**
    - 基于颜色的聚类

![rcnn](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/rcnn.32bd4q67zto0.png)



### Fast RCNN

![fastrcnn](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/fastrcnn.2rhxtqzyyda0.png)

#### ROI Pooling

![roi](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/roi.18c7rzzo73cw.jpg)

![fea](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/fea.2i6kkb0aasm0.png)



- ROI pooling 输出大小 2 * 2
  - max or mean
- 缩小

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/out.4hg1twlkpmk0.jpg" alt="out" style="zoom:56%;" />         <img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/out2.20job7xumesg.jpg" alt="out2" style="zoom:46%;" />

- 放大
  - 类似于图像调整大小
  - 通过最近邻点进行插值

![out3](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/out3.79ju03fcwgo0.png)



### ROI Align in Mask-RCNN

- 图像调整大小：插值比最近邻更好
- 特征图调整大小相同：ROl Pooling -> ROlAlign

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/align.r4z4su88cxc.jpg" alt="align" style="zoom:54%;" />

- Dash grid：5 $\times$ 5 feature map 
- **Solid Rectangle**：$H \times W$ ROI at feature map 
- Output：2 $\times$ 2 solid grid

1. 每个单元格 2 $\times$ 2  输出用4点采样
2. 每个点都是 **bilinear interpolation**（双线性插值）成虚线网格
3. 每个单元格是最大/平均的4分的池



**bilinear interpolation**

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/bilinear.6fd6nbbw1y80.jpg" alt="bilinear" style="zoom:43%;" />

- $R_1:$ <img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/r1.20pdwk9g1veo.jpg" alt="r1" style="zoom:53%;" />
- $R_2:$ <img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/r2.6pecmepek580.jpg" alt="r2" style="zoom:53%;" />

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/f1.3ue3ip60nbm0.jpg" alt="f1" style="zoom:53%;" /> <img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/f2.98x81o4rzvc.jpg" alt="f2" style="zoom:52%;" />



**Eg**.

![align](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/align.7gty06lpfn40.png)

![align2](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/align2.1k11ucxmzthc.png)

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/align3.6dr39sqxt000.png" alt="align3" style="zoom:40%;" />

- 每个单元格
  - $Width = 6.25/3=2.0833$
  - $Height = 4.53 / 3 = 1.51$

- 其他单元格中的四个点类似



**每个点做 Interpolation** 

| ![Interpolation](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/Interpolation.2hsl7s0ilga0.png) | ![2](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/2.65zy1ajlbyc0.png) |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| ![3](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/3.6402egu9qvk0.png) | ![4](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/4.4uvsyn0mqbk0.png) |

结果：

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/res.1zrwpdtpzc74.png" alt="res" style="zoom:50%;" />

- 重复以上操作即可得到 ROIAlign



<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/res2.3uc864deul40.jpg" alt="res2" style="zoom:46%;" />

### Faster RCNN

![fasterrcnn](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/fasterrcnn.1t92l32yupc0.jpg)

#### Region Proposal Network (RPN)

- input
  - Feature map
  - Anchors
- Output:
  - Object proposals (x, y, h, w)

![anchors](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/anchors.6sycqk9dbx40.png)

 **RPN determines**

- Object or NOT-Object
  - 2k scores
- If yes, [x,y,h,w] of the object box 
  - 4k coordinates

- 不关心对象的类别

![rpn](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/rpn.3y1xvm8y57m0.jpg)

#### 步骤

**Steps**

1. **CNN** $\rightarrow$ Feature Map

2. **RPN** $\rightarrow$ Proposals

3. **ROI** $\rightarrow$ Pooling

4. **CNN + MLP** $\rightarrow$ bounding boxes

**Losses:**

1. **RPN classify** object / not object

2. **RPN regress** box coordinates

3. Final box **classification**

4. Final box **coordinates**

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/rcnn.2ac2t2ym0n0g.jpg" alt="rcnn" style="zoom:53%;" />

### Mask RCNN

![MaskRCNN](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/MaskRCNN.sfjs0ucw5lc.jpg)

- Input
  - Image

- Output
  - Object boxes
  - Per-pixel mask

- 对 Faster RCNN 的两项改进
  - ROI Align
  - Object detection + Instance Segmentation（实例分割（把每个人分开））

### 总结

![s](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/s.4xb8nqp8v5a0.png)



## One Stage

**No ROI Pooling**

![one](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/one.4znmgycm1us0.png)

With **each cell**:

- Regression of $B$ boxes 

- dx, dy, dh, dw（偏差）, confidence（类别概率）
  - “d” means relative to prior box

- Classification of this cell：$C$ classes

- Output：
  - $7\times7\times(B\times5+C)$   （不包含背景类）
  -  $7\times7\times(B\times(4+C))$  （包含背景类）



i.e. $7\times7$ feature map after CNN

Each cell corresponds to $B$ prior bounding boxes, here  $B=3$ 



### SSD

![ssd](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/ssd.1sl580hso5vk.png)

## Loss Function for 2D Detectors

- Ground truth boxes:  $\{x^g,y^g,w^g,h^g,p\}, p$ is the label
- Network output: a set of boxes $\{x,y,w,h,{c_0,c_1,...,c_k}\}$
  - Category 0 is background / not-object
- Loss function contains two parts
  - Classification for both **positive** and **negative** matches, CrossEntropyLoss
    - <img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/cls.2bcb9bmg1134.png" alt="cls" style="zoom:50%;" /> 
  - Regression for **positive** matches:
    - <img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/reg.727k0lnbma80.png" alt="reg" style="zoom:43%;" /> 

## Training/Inference Steps for 2D Detectors

**Training steps:**

- 建立 **positive matching** ——哪些输出框与地面实况框相关联
  - IoU > threshold  **or** 具有地面实况框之一的最大 IoU

- 建立 **negative matching** ——哪些输出框不匹配任何地面实况框
  - IoU< threshold

**Inferencesteps:**

- 选择分类分数高的框
- 非最大抑制 (Non-Maximum Suppression (NMS))



## 总结

- **Two stage** 方法通常更准确，但速度较慢
- 相同方法的速度和准确度可能会有很大不同，具体取决于
  - 网络设计
  - 训练配置
  - 参数设置，
  - 图像/特征图分辨率，
  - 锚点/先验框的数量，
  - 如何选择锚点/优先框
  - $... ...$

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/sum.2qz08cw1yys.png" alt="sum" style="zoom:50%;" />

