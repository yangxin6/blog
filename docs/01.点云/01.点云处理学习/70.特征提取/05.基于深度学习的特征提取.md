---
title: USIP
date: 2021-10-06 13:00:00
permalink: /pages/C9vUE1
categories: 
  - 点云
tags: 
  - USIP
author: 
  name: yangxin
  link: https://github.com/yangxin6/3DPointCloud
---


- 极少数用于点云特征检测的深度学习方法

  - “特征”的定义尚不清楚
  - 没有可用的注释/数据集
  - 点云处理的其他难点
  - 旋转等方差
  - 稀疏性
  - ......



- 2020年之前大概只有2种方法
  - **USIP**： **Unsupervised** Stable Interest Point Detection from 3D Point Clouds（来自 3D 点云的**无监督**稳定兴趣点检测）
  - **3DFeat Net**：用于点云配准的弱监督局部 3D 特征



## USIP Feature

![usip](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/usip.1bjm65zgjpi8.png)

**无监督**让网络决定什么是关键点



**主要思想**

- 无论我们如何变换对象，**特征点**仍然是关键点
- “特征点”的概念取决于**规模/细节水平**
  - 如果我们看大尺度，一个物体的中心是一个关键点
  - 如果我们看轮胎的表面，轮胎的纹理是关键点，如果我们在车辆的尺度上，则不是关键点



## 结构

![a](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/a.5kxa39im7x40.png)



- 符号
  - 点云：$X = [X_1,...,X_N] \in R^{3\times N}$
  - 矩阵变换：$T\in SE(3),i.e.,$ <img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/t.4c9r90wutp40.png" alt="t" style="zoom:30%;" /> 

- 输入
  - 点云：$X$
- 输出
  - $M$ 特征点 $Q=\{Q_1,...,Q_M\},Q_i\in R^{3\times M}$
  - 不确定性 $\Sigma = \{\sigma_1,...\sigma_M\},\sigma_i \in R^+$



## 训练流程

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/train.3ya7mt8qqbm0.png" alt="train" style="zoom:40%;" /> 



## Probabilistic Chamfer Loss

**Standard Chamfer Loss** 标准倒角损失

![scl](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/scl.6zhz7qtgg0w0.jpg)

问题：

- **根据预测的不确定性添加权重**
- **感知域是有限的**



提出：

**Probabilistic Chamfer Loss**：根据预测的不确定性添加权重 $\Sigma$

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/lo.2eqb5bd7vnfo.png" alt="lo" style="zoom:50%;" />

- 如何将不确定性 $\sigma_i \in R^+ $ 转化为概率
  - 考虑一对特征点：$\{Q_i,\sigma_i\} \ and \ \{Q_j^{'},\sigma_j^{'}\}$
  - 距离： $d_{ij} = ||Q_i-Q_j^{'}||_2$
-  建立$Q_i,Q_i^{'}$ 是相同关键点的概率模型（它们是匹配的）：
  - ![p](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/p.688e251w5lo0.png) 
- 这是一个指数分布
  - $d_{ij}$ 是随机变量
  - $\sigma_{ij}$ 是指数分布的参数，通过 FPN给出
- 对于 $Q_i$ 如何确定哪个 $\{Q_i^{'},\sigma_i^{'}\}$ 是最匹配的
  - 与 Standard Chamfer Loss 类似

![mlp](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/mlp.51q29mq5tn80.png)

最优化问题 $\Rightarrow$ 最大似然

- 最终损失，最大化概率 $\Rightarrow$ 最小化 -log的概率
  - <img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/mlp.7fqno28arz80.png" alt="mlp" style="zoom:40%;" /> 

- 事实上，根据我们的概率倒角损失，不确定性 $\sigma$ 有物理意义



### 物理意义

- 损失函数
  - <img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/loss.2n97znor1ao0.jpg" alt="loss" style="zoom:50%;" /> 

- 计算 $p$ 关于 $\sigma_{ij}$ 的一阶导数
  - <img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/p.6c8fym9pack0.jpg" alt="p" style="zoom:50%;" /> 
- 求极值点：
  - <img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/s.78tg0sqvv180.jpg" alt="s" style="zoom:50%;" /> 

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/plot.29nnpz0fj4pw.png" alt="plot" style="zoom:50%;" />

- **这意味着最好的 $\sigma_{ij}$ 等于 $d_{ij}$**
  - 神经网络正在预测这个匹配



**E.g.**

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/eg.otuefnoxgl.png" alt="eg" style="zoom:30%;" />

## Degeneracy and Receptive Field

Degeneracy and Receptive Field **退化和感受野**

- 如果网络将对象中心预测为关键点

  - <img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/q.9kfycknwjnw.png" alt="q" style="zoom:50%;" /> 
  - 不管如何旋转平移，中心点仍是中心点  $L_c = 0$ 
  - 中心点也是一个物体的特征点

  

- 如果网络输出点在主轴（principle axis） 上，损失 $L_c$ 会很小
  - 无论变换什么，主轴都不会改变 
  - 类似于对象中心



**E.g.**

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/pr.452p4trt94u0.png" alt="pr" style="zoom:30%;" />



- 有两种退化情况：
  - **对象中心**
  - **主轴**

- 如何避免：
  - 限制 FPN 的感知域
- 关键点的感知域
  - 在预测这个关键点时，FPN 可见的点是什么
  - 如果 FPN 只看到物体的一小部分，它无法预测中心/主轴在哪里



## FPN Design

**FPN Design** **感知域**

- FPN 可以是任何网络，只有一个要求
  - 每个关键点的感受野是可控的。
- 例如，我们可以使用 PointNet ++ 作为 FPN 
  - <img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/pp.3wd6snp9vo00.png" alt="pp" style="zoom:50%;" /> 每个点都有有限的感知域
- USIP 使用 **SO-Net** 作为 **FPN**
  - SO-Net：用于点云分析的自组织网络
  - 更好的性能；更好的对点云的空间建模；自适应各种点密度



## Loss Function

**Point-to-Point Loss**

-  FPN 得到的特征点，不一定在物体上，可能会存在偏移
  - 只需通过标准倒角添加约束损失
  - <img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/ppl2.6ppo9hqiu7g0.jpg" alt="ppl2" style="zoom:70%;" />  
- 最后的损失函数：
  - $L=L_c+\lambda L_{point}$

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/ppl.1ubh0qo7k9k0.jpg" alt="ppl" style="zoom:43%;" />

## USIP Results

### ModelNet40

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/m40.2qi73kcg3go0.jpg" alt="m40" style="zoom:50%;" />

### Oxford RobotCar

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/Car.4w0gxb5dc8s0.jpg" alt="Car" style="zoom:50%;" />

### KITTI

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/Kitti.1zjcbdo0od5s.jpg" alt="Kitti" style="zoom:50%;" />



## 总结

**思想**

- 预测关键点位置和不确定性
- 概率倒角损失的无监督训练
- 可控感受野防止退化



**优势**

- 数据驱动
- 对噪声/稀疏性稳健
- 非常稳定和可重复





**传统人工**：不稳定，对噪音敏感。 但是不需要训练

- **Harris family**
  - Harris **3D** with/without intensity
  - Harris **6D** with intensity
- **ISS**



**深度学习**：稳定而坚固。 但需要训练（无人监督）。

- **USIP**

