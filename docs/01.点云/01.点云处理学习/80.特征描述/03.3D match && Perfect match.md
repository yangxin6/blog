---
title: 3D match && Perfect match
date: 2021-10-27 19:10:00
permalink: /pages/fi69Qu
categories: 
  - 点云
tags: 
  - 3D match,Perfect match
author: 
  name: yangxin
  link: https://github.com/yangxin6/3DPointCloud
---

**为什么需要深度学习 Descriptor**

- 所有传统的 Descriptor 都是基于几何学的，例如：
  - 关键点周围的表面法线变化
  - 关键点周围的点分布
- 在以下情况下，它们是不可靠的
  - 噪声
  - 遮挡/形状不完整
  - 稀疏度
- 深度学习
  - 包括语义信息
  - 更加智能的几何编码方式
  - 对噪音有很强的抵抗力





- **3DMatch**：从RGB D重构中学习局部几何描述符
- **The Perfect Match**: 用平滑密度进行三维点云匹配
- **PPFNet**：用于稳健的三维点匹配的全局上下文感知局部特征
- **PPF FoldNet**：无监督地学习旋转不变的三维局部描述符
- CGF：学习紧凑的几何特征
- 3DFeat Net: 用于点云注册的弱监督局部三维特征
- USIP：来自三维点云的无监督稳定兴趣点检测
- ......



## 3DMatch

### 思路

- 输入：3D patch，voxel grid of $30 \times 30 \times 30$
  - 截断距离函数 Truncated Distance Function (TDF) /二元体素网格/概率体素网格 ...
- 输出：Descriptor for that patch, 512个向量

![3dm](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/3dm.5qw86hpvew00.jpg)



### 训练

- 输入：2 patches
- 输出：2 patches
- 如果这 2 patches 来自同一个
  - 相似 similar
- 否则
  - 不同 different
- 2 个问题：
  - 如何建立 dataset
  - 如何定义 "similar" / "different"

### Dataset

- 利用RGB-D重构
  - 从多个RGB-D帧重建
  - 知道每一帧的位置
- **Positive** pairs of patches:
  - 相同的物理位置（例如：<0.05米）
  - 隔至少1米获取的不同帧（不同的角度）
- **Negative** pairs:
  - 至少间隔0.1米



### Contrastive Loss

Contrastive Loss 对比损失函数

（二元组）

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/cl.1fg0x4724n28.png" alt="cl" style="zoom:30%;" /> 

考虑的是**绝对距离** 而不是相对距离



### t-SNE embedding of descriptors

![tSNE](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/tSNE.q0b660327ts.png)

### Results

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/res.oc4dkvi3mr.jpg" alt="res" style="zoom:50%;" />

- A, B: 从不同的角度进行RGBD扫描视点

- C: 用3DMatch注册+ RANSAC（在第9讲中涉及）。

- 右边的3列：3NN 在B中搜索A的斑块，基于基于3DMatch描述符的3NN搜索。

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/recall.13w4389hzcu8.png" alt="recall" style="zoom:40%;" />

旋转之后3DMatch 网络就没有用了



### Triplet Loss

（三元组）

考虑**相对位置**

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/3l.7f5l3omppn40.png" alt="3l" style="zoom:40%;" /> 

要求：

Negative到 Anchor 的距离 大于 Positive 到 Anchor 的距离



#### 训练方法

$L_i = \max(d_i(a,p)-d_i(a,n)+\gamma,0)$

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/3l2.27yvnqxklhj.png" alt="3l2" style="zoom:50%;" /> 

#### Triplet Mining

- 一般原则
  - 通常三元组应该包含 semi-hard and/or hard ones
  - 试验 验证/测试集 以确定最佳配置和 $\gamma$
  - In Defense of the Triplet Loss for Person Re-ldentification, Alexander Hermans et.al. 讲了很多 Triplet Mining 的方法
- Offline negative mining - 效率不高
  - 预构建 $[a,p,n]$
  - 在每个训练 epoch 之后
    - 遍历数据集
    - 为每个Anchor 选择 positive & negative 样本

#### Online Triplet Mining

**Example 1 with Descriptors**

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/otm1.5kcp8xlokt00.png" alt="otm1" style="zoom:50%;" />



**Online Triplet Mining  Example 2with Descriptors**

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/otm2.4tgeml9w4ve0.png" alt="otm2" style="zoom:50%;" />

## The Perfect Match

The Perfect Match: 3D Point Cloud Matching with Smoothed Densities

改进 3D Match

- LRF
- Loss -> 三元组

### Local Reference Frame (LRF)

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/lrf.1lmul2uxv03k.png" alt="lrf" style="zoom:40%;" /> 

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/lrf2.4av1q8ek7uu0.png" alt="lrf2" style="zoom:50%;" />



**The Perfect Match**

![pm](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/pm.1ln1oaqihgrk.png)



## 3DMatch/Perfect Match

![3dmpm](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/3dmpm.6vkokcnr9fc0.png)

